# 
A full-stack Vision-Language AI pipeline that simulates realistic human activity scenes using Stable Diffusion, labels them with YOLOv8, captions them with BLIP, and reasons about them with LLaMA-3.  
Built entirely using synthetic data for ethical, flexible, and scalable scene understanding.

> No real-world data.  
> No manual annotation.  
> Fully AI-generated, AI-labeled, and AI-reasoned.
